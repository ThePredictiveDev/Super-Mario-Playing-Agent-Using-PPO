{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a113b64-ee6a-49f7-a2f0-8f9865a1f336",
   "metadata": {},
   "source": [
    "# Creating a Simple Agent to Play Super Mario Using PPO RL Algorithm Applied on a CNN "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f28816-9ce1-4636-88c3-5c27e4b568f8",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072692d0-89ea-4db0-9512-131d742de651",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use Older Version of Pip, Wheel and Setuptools for the project\n",
    "\n",
    "import gym_super_mario_bros as gsbm #Use Version 7.3.0\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n",
    "import gym #Use OpenAI Gym V0.21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e411e0f-820c-4125-b6c9-91517a4a3c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.wrappers import GrayScaleObservation\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b8fc8e-09a2-4d69-b78d-9d6c5aa8b5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from stable_baselines3 import PPO #Use Older Version of Stable-Baselines3 (v1.5 or v1.6)\n",
    "from stable_baselines3.common.callbacks import BaseCallback #Use Older Version of Stable-Baselines3 (v1.5 or v1.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0477f4c9-eaf5-4c02-8954-545fd64097c6",
   "metadata": {},
   "source": [
    "## Applying Preprocessing to Gym Environment Using Imported Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73223a1-b032-4b5f-a93b-3bc73fabbc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gsbm.make('SuperMarioBros-v0') #Making a custom Mario gym environment\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT) #Using to reduce action space\n",
    "env = GrayScaleObservation(env, keep_dim=True) #Wrapping to convert RGB --> GrayScale\n",
    "env = DummyVecEnv([lambda: env]) #Wrapping in dummy env\n",
    "env = VecFrameStack(env, 4, channels_order='last') #Stacking frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f364558a-68ae-4941-8bc0-3cea99d3ceba",
   "metadata": {},
   "source": [
    "## Defining a Callback Function to Save Model Every N TimeStamp During Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cad6d29-d31a-411f-a894-d09ec5885fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "    \n",
    "    def __init__ (self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "        \n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "            \n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self .model.save(model_path)\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efea039-e2f6-4119-91ff-c51e7006e2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining folders for storing models\n",
    "CHECKPOINT_DIR = './RL_MODEL/' \n",
    "#defining folders for storing logs\n",
    "LOG_DIR = './logs/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c70988-6aeb-4ff9-8b19-8ba2c0966d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up the callback function\n",
    "callback = TrainAndLoggingCallback(check_freq=100000, save_path = CHECKPOINT_DIR) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98111967-3c70-4d53-942f-830e25a36eb9",
   "metadata": {},
   "source": [
    "## Setting Up and Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ed9be0-fbfb-4275-85ca-4dd4b5a9233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up the model\n",
    "model = PPO('CnnPolicy', env, verbose=1, tensorboard_log = LOG_DIR, learning_rate = 0.000001, n_steps = 512 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26578ce6-c2eb-4fde-881b-478775fab0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up the learning process of the model\n",
    "model.learn(total_timesteps = 10000000, callback=callback) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccef7537-157b-408a-800c-c21a91afbca7",
   "metadata": {},
   "source": [
    "## Making Predictions Using the Model (Playing the Game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e39da4b-6369-42db-97c0-f14205ab4b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the model\n",
    "model = PPO.load('./RL_MODEL/best_model_5100000') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e11740-ab9b-4293-aaf6-2e260b44b125",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing the environment\n",
    "state = env.reset() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e76ab1-8976-4914-b16c-612f0b0cba07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rendering the environment with actions being predicted by the agent, essentially making it play the game\n",
    "while True:\n",
    "    action, _ = model.predict(state)\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0701cc6-ae97-4796-ae64-e897b28928a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close() #used to close the game post interrupting above loop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
